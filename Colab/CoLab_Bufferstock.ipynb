{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Setup](#toc1_)    \n",
    "- 2. [Imports](#toc2_)    \n",
    "- 3. [Model](#toc3_)    \n",
    "- 4. [DL](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy this nootebook to your **Google Drive**\n",
    "2. Open the notebook with **Google Colab**\n",
    "3. Runtime -> Change runtime type -> T4\n",
    "4. Create **Personal access tokens (classic)** for github at https://github.com/settings/tokens. Under **Select scopes** choose **repo** box\n",
    "5. Paste in below.\n",
    "6. Run the notebook (you might need to grant access to your drive in a pop-up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_PERSONAL_ACCESS_TOKEN = 'YOUR_GITHUB_ACCESS_TOKEN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only run below once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = '/content/drive/MyDrive/ImperfectProblemSolving/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(REPO):\n",
    "    !git clone https://$GITHUB_PERSONAL_ACCESS_TOKEN@github.com/jacoropke/ImperfectProblemSolving.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install EconModel\n",
    "!pip install ConSav\n",
    "!pip install pynvml\n",
    "!pip install torch\n",
    "!pip install line_profiler\n",
    "!pip install papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd EconDLSolvers\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc1_'></a>[Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams.update({\"axes.grid\" : True, \"grid.color\": \"black\", \"grid.alpha\":\"0.25\", \"grid.linestyle\": \"--\"})\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EconDLSolvers import choose_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BufferStockModel import BufferStockModelClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 <a id='toc2_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algoname = 'DeepSimulate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU\n"
     ]
    }
   ],
   "source": [
    "device = choose_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BufferStockModelClass(algoname=algoname,device=device,par={'Nstates_fixed':0},train={'K_time':0.5},show_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a id='toc3_'></a>[Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started solving: 2025-01-21 14:17:25\n",
      "k =     0 of inf: sim.R =  -0.73789364 [best:  -0.73789364] [0.4 secs] [value_epochs =   0] [policy_epochs =   1] [  0.01 mins]\n",
      "k =    50 of inf: sim.R =  -0.32301685 [best:  -0.32301685] [0.2 secs] [value_epochs =   0] [policy_epochs =   1] [  0.04 mins]\n",
      "k =   100 of inf: sim.R =  -0.31363919 [best:  -0.31363919] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.07 mins]\n",
      "k =   150 of inf: sim.R =  -0.30765101 [best:  -0.30765101] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.11 mins]\n",
      "k =   200 of inf: sim.R =  -0.30302531 [best:  -0.30302531] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.13 mins]\n",
      "k =   250 of inf: sim.R =  -0.30067715 [best:  -0.30067715] [0.2 secs] [value_epochs =   0] [policy_epochs =   1] [  0.17 mins]\n",
      "k =   300 of inf: sim.R =  -0.29887009 [best:  -0.29887009] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.21 mins]\n",
      "k =   350 of inf: sim.R =  -0.29746717 [best:  -0.29746717] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.25 mins]\n",
      "k =   400 of inf: sim.R =  -0.29661193 [best:  -0.29661193] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.27 mins]\n",
      "k =   450 of inf: sim.R =  -0.29604253 [best:  -0.29604253] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.30 mins]\n",
      "k =   500 of inf: sim.R =  -0.29570863 [best:  -0.29570863] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.33 mins]\n",
      "k =   550 of inf: sim.R =  -0.29547521 [best:  -0.29547521] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.36 mins]\n",
      "k =   600 of inf: sim.R =  -0.29527169 [best:  -0.29527169] [0.2 secs] [value_epochs =   0] [policy_epochs =   1] [  0.44 mins]\n",
      "k =   650 of inf: sim.R =  -0.29515305 [best:  -0.29515305] [0.1 secs] [value_epochs =   0] [policy_epochs =   1] [  0.48 mins]\n",
      "Terminating after 678 iter, max time 0.5 mins reached\n",
      "R = -0.2951, time = 0.5 mins, iter = 678, policy epochs = 1.00, value epochs = 0.00\n"
     ]
    }
   ],
   "source": [
    "model.solve(do_print=True,do_print_all=False,show_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('timings'): os.mkdir('timings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating after 1027 iter, max time 0.5 mins reached\n",
      "\n",
      "*** Profile printout saved to text file 'timings/DeepSimulate.txt'. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 30.1955 s\n",
      "File: c:\\users\\jzd145-unicph\\repos\\imperfectproblemsolving\\econdlsolvers\\EconDLSolvers\\DLSolver.py\n",
      "Function: solve at line 647\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   647                                               def solve(self,do_print=False,do_print_all=False,show_memory=False,postfix=''):\n",
      "   648                                                   \"\"\" solve model \"\"\"\n",
      "   649                                           \n",
      "   650         1        124.0    124.0      0.0          if not torch.cuda.is_available(): show_memory = False\n",
      "   651                                           \n",
      "   652         1      40430.0  40430.0      0.0          timestamp = solving_json(postfix)\n",
      "   653         1         31.0     31.0      0.0          t0_solve = time.perf_counter()\n",
      "   654                                           \n",
      "   655         1          5.0      5.0      0.0          if do_print_all: do_print = True\n",
      "   656         1          4.0      4.0      0.0          if do_print: print(f\"started solving: {timestamp}\")\n",
      "   657                                           \n",
      "   658                                                   # a. unpack\n",
      "   659         1          8.0      8.0      0.0          sim = self.sim\n",
      "   660         1         17.0     17.0      0.0          train = self.train\n",
      "   661         1          8.0      8.0      0.0          info = self.info\n",
      "   662                                                   \n",
      "   663         1          4.0      4.0      0.0          if show_memory: \n",
      "   664                                                       free_GB_ini = get_free_memory(train.device)\n",
      "   665                                                       print(f'initial: {free_GB_ini:.2f}GB free')\n",
      "   666                                           \n",
      "   667         1         10.0     10.0      0.0          if 'solve_in_progress' in self.info:\n",
      "   668                                                       continued_solve = True\n",
      "   669                                                   else:\n",
      "   670         1         11.0     11.0      0.0              self.info['solve_in_progress'] = True\n",
      "   671         1          4.0      4.0      0.0              continued_solve = False\n",
      "   672                                           \n",
      "   673         1          3.0      3.0      0.0          if not continued_solve:\n",
      "   674         1          5.0      5.0      0.0              self.info['time'] = 0.0\n",
      "   675         1          6.0      6.0      0.0              self.info['time.update_NN'] = 0.0\n",
      "   676         1          6.0      6.0      0.0              self.info['time.update_NN.train_value'] = 0.0\n",
      "   677         1          3.0      3.0      0.0              self.info['time.update_NN.train_policy'] = 0.0\n",
      "   678         1         11.0     11.0      0.0              self.info['time.scheduler'] = 0.0\n",
      "   679         1          5.0      5.0      0.0              self.info['time.convergence'] = 0.0\n",
      "   680         1          5.0      5.0      0.0              self.info['time.update_best'] = 0.0\n",
      "   681         1          5.0      5.0      0.0              self.info['time._simulate_training_sample'] = 0.0\n",
      "   682         1          5.0      5.0      0.0              self.info['time.simulate_R'] = 0.0\n",
      "   683                                           \n",
      "   684                                                   # b. initialize best\n",
      "   685         1          3.0      3.0      0.0          if not continued_solve:\n",
      "   686                                           \n",
      "   687         1         23.0     23.0      0.0              best = info['best'] = SimpleNamespace()\n",
      "   688         1          8.0      8.0      0.0              best.k = -1\t\t\n",
      "   689         1          5.0      5.0      0.0              best.time = 0.0\n",
      "   690         1         21.0     21.0      0.0              best.R = -np.inf\n",
      "   691         1         12.0     12.0      0.0              best.policy_NN = None\n",
      "   692         1          7.0      7.0      0.0              best.value_NN = None\n",
      "   693                                           \n",
      "   694                                                   else:\n",
      "   695                                           \n",
      "   696                                                       best = info['best']\n",
      "   697                                                       \n",
      "   698                                                   # c. loop over iterations\n",
      "   699         1          4.0      4.0      0.0          if not continued_solve:\n",
      "   700         1        137.0    137.0      0.0              epsilon_sigma = info['epsilon_sigma'] = deepcopy(train.epsilon_sigma)\n",
      "   701         1          5.0      5.0      0.0              k = 0\n",
      "   702                                                   else:\n",
      "   703                                                       epsilon_sigma = info['epsilon_sigma']\n",
      "   704                                                       k = info['iter']\n",
      "   705                                           \n",
      "   706      1027       6562.0      6.4      0.0          while True:\n",
      "   707                                                       \n",
      "   708      1027      22620.0     22.0      0.0              t0_k = time.perf_counter()\n",
      "   709      1027       9077.0      8.8      0.0              train.k = k\n",
      "   710                                           \n",
      "   711      1027      18791.0     18.3      0.0              info[('value_epochs',k)] = 0 # keep track of number of value epochs (updated in algo)\n",
      "   712      1027       9697.0      9.4      0.0              info[('policy_epochs',k)] = 0 # keep track of number of policy epochs (updated in algo)\n",
      "   713                                           \n",
      "   714                                                       # i. simulate training sample\n",
      "   715      1027      10283.0     10.0      0.0              do_exo_actions = k < train.do_exo_actions_periods # exo actions defined in draw_exo_actions\n",
      "   716      1027   15383076.0  14978.7      5.1              self._simulate_training_sample(epsilon_sigma,do_exo_actions)\n",
      "   717                                                       \n",
      "   718                                                       # update exploration\n",
      "   719      1027       9483.0      9.2      0.0              if epsilon_sigma is not None:\n",
      "   720                                                           epsilon_sigma *= train.epsilon_sigma_decay\n",
      "   721                                                           epsilon_sigma = np.fmax(epsilon_sigma,train.epsilon_sigma_min)\n",
      "   722                                           \n",
      "   723                                                       # ii. update neural nets\n",
      "   724      1027      11201.0     10.9      0.0              t0 = time.perf_counter()\n",
      "   725      1027  254816131.0 248117.0     84.4              self.algo.update_NN(self) # is different for each algorithm\n",
      "   726      1027      66706.0     65.0      0.0              info['time.update_NN'] += time.perf_counter() - t0\n",
      "   727                                           \n",
      "   728                                                       # iii. scheduler step\n",
      "   729      1027       9061.0      8.8      0.0              t0 = time.perf_counter()\n",
      "   730      1027     510372.0    497.0      0.2              self.algo.scheduler_step(self)\n",
      "   731      1027      20317.0     19.8      0.0              info['time.scheduler'] += time.perf_counter() - t0\n",
      "   732                                           \n",
      "   733                                                       # iv. print and termination\n",
      "   734      1027      23513.0     22.9      0.0              info[('k_time',k)] = time.perf_counter()-t0_solve + info['time']\n",
      "   735      1027      16122.0     15.7      0.0              info[('update_time',k)] = time.perf_counter()-t0_k\n",
      "   736      1027      19880.0     19.4      0.0              if not train.sim_R_freq is None and k % train.sim_R_freq == 0:\n",
      "   737                                           \n",
      "   738                                                           # o. update best\n",
      "   739        21   20474393.0 974971.1      6.8                  self._update_best()\n",
      "   740                                           \n",
      "   741                                                           # oo. print\n",
      "   742        21        162.0      7.7      0.0                  if do_print: self._print_progress(t0_k,t0_solve)\n",
      "   743                                           \n",
      "   744                                                           # ooo. convergence\n",
      "   745        21        261.0     12.4      0.0                  t0 = time.perf_counter()\n",
      "   746                                                           \n",
      "   747        21     696930.0  33187.1      0.2                  terminate = self.convergence(postfix=postfix)\n",
      "   748        21        853.0     40.6      0.0                  info['time.convergence'] += time.perf_counter() - t0\n",
      "   749                                           \n",
      "   750                                                           # oooo. termination\n",
      "   751        21        647.0     30.8      0.0                  if info[('k_time',k)]/60 > train.K_time_min: # above minimum time\n",
      "   752                                                               if terminate: break # convergence criterion satisfied\n",
      "   753                                                       \n",
      "   754                                                       else:\n",
      "   755                                           \n",
      "   756      1006      31818.0     31.6      0.0                  info[('R',k)] = np.nan\t\t\n",
      "   757      1006       4709.0      4.7      0.0                  if do_print_all: self._print_progress(t0_k,t0_solve)\n",
      "   758                                                       \n",
      "   759                                                       # v. termination from policy loss\n",
      "   760      1027      11513.0     11.2      0.0              if train.terminate_on_policy_loss and info[('policy_loss',k)] < train.tol_policy_loss:\n",
      "   761                                                           self._update_best() # final update\n",
      "   762                                                           k += 1\n",
      "   763                                                           print(f'Terminating after {k} iter, policy loss lower than tolerance')\n",
      "   764                                                           break\n",
      "   765                                                       \n",
      "   766                                                       # vi. termination from time\n",
      "   767      1027      21606.0     21.0      0.0              time_tot = (time.perf_counter()-t0_solve)/60 + info['time']/60\n",
      "   768      1027      13548.0     13.2      0.0              if time_tot > train.K_time:\n",
      "   769         1    1819417.0    2e+06      0.6                  self._update_best() # final update\n",
      "   770         1         15.0     15.0      0.0                  k += 1\n",
      "   771         1       1848.0   1848.0      0.0                  print(f'Terminating after {k} iter, max time {train.K_time} mins reached')\n",
      "   772         1          7.0      7.0      0.0                  break\n",
      "   773                                                           \n",
      "   774                                                       # vii. check if solving.json has been updated for manual termination\n",
      "   775      1026    7683096.0   7488.4      2.5              manuel_terminate = check_solving_json(timestamp)\n",
      "   776      1026       7469.0      7.3      0.0              if manuel_terminate:\n",
      "   777                                                           self._update_best() # final update\n",
      "   778                                                           k += 1\n",
      "   779                                                           print(f'Terminating after {k} iter, manuel termination')\n",
      "   780                                                           break\n",
      "   781                                           \n",
      "   782                                                       # vii. terminate from too many iterations\n",
      "   783      1026      11327.0     11.0      0.0              k += 1\n",
      "   784      1026      21144.0     20.6      0.0              if k >= train.K: \n",
      "   785                                                           self._update_best() # final update\n",
      "   786                                                           print(f'Terminating after {k} iter, max number of iterations reached')\n",
      "   787                                                           break            \n",
      "   788                                           \n",
      "   789                                                   # d. load best solution\n",
      "   790         1         13.0     13.0      0.0          t0 = time.perf_counter()\n",
      "   791                                           \n",
      "   792         1          7.0      7.0      0.0          if self.policy_NN is not None: \n",
      "   793         1         10.0     10.0      0.0              if not best.policy_NN is None:\n",
      "   794         1      11250.0  11250.0      0.0                  self.policy_NN.load_state_dict(best.policy_NN)\n",
      "   795                                                   \n",
      "   796         1         16.0     16.0      0.0          if self.value_NN is not None: \n",
      "   797                                                       if not best.value_NN is None:\n",
      "   798                                                           self.value_NN.load_state_dict(best.value_NN)\n",
      "   799                                                               \n",
      "   800         1         43.0     43.0      0.0          info['time.update_best'] += time.perf_counter() - t0\n",
      "   801                                           \n",
      "   802                                                   # e. final simulation\n",
      "   803         1          8.0      8.0      0.0          t0 = time.perf_counter()\n",
      "   804         1     113901.0 113901.0      0.0          self.simulate_R()\n",
      "   805         1         23.0     23.0      0.0          info['time.update_best'] += time.perf_counter() - t0\n",
      "   806                                           \n",
      "   807                                                   # f. store\n",
      "   808         1         17.0     17.0      0.0          info['R'] = best.R\n",
      "   809         1         19.0     19.0      0.0          info['time'] += time.perf_counter()-t0_solve\n",
      "   810         1         17.0     17.0      0.0          info['iter'] = k\n",
      "   811         1      14476.0  14476.0      0.0          info[('value_epochs','mean')] = np.mean([info[('value_epochs',k)] for k in range(info['iter'])])\n",
      "   812         1       9584.0   9584.0      0.0          info[('policy_epochs','mean')] = np.mean([info[('policy_epochs',k)] for k in range(info['iter'])])\n",
      "   813                                           \n",
      "   814         1          6.0      6.0      0.0          if do_print: self.show_info()\n",
      "   815                                           \n",
      "   816                                                   # g. extra: multiples simulations of R\n",
      "   817         1          5.0      5.0      0.0          if do_print and self.sim.reps > 0: print('Simulating multiple Rs')\n",
      "   818         1        520.0    520.0      0.0          Rs = self.simulate_Rs()\n",
      "   819         1         12.0     12.0      0.0          info['Rs'] = Rs\n",
      "   820                                               \n",
      "   821                                                   # h. extra: simulation with epsilon shocks\n",
      "   822         1         10.0     10.0      0.0          if train.do_sim_eps and not epsilon_sigma is None:\n",
      "   823                                           \n",
      "   824                                                       if do_print: print('Simulating with exploration')\n",
      "   825                                           \n",
      "   826                                                       self.sim_eps = deepcopy(sim)\n",
      "   827                                                       eps = self.draw_exploration_shocks(epsilon_sigma,self.sim_eps.N).to(train.dtype).to(train.device)\n",
      "   828                                                       simulate(self,self.sim_eps,eps=eps) # note: same initial states and shocks as in .sim are used\n",
      "   829                                           \n",
      "   830                                                   else:\n",
      "   831                                           \n",
      "   832         1         14.0     14.0      0.0              self.sim_eps = None\n",
      "   833                                                   \n",
      "   834                                                   # h. empty cache\n",
      "   835         1          6.0      6.0      0.0          if show_memory: \n",
      "   836                                                       free_GB_fin = get_free_memory(train.device)\n",
      "   837                                                       print(f'solve(): {free_GB_ini-free_GB_fin:.2f}GB allocated')\n",
      "   838                                           \n",
      "   839         1        185.0    185.0      0.0          if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
      "   840                                           \n",
      "   841         1          6.0      6.0      0.0          if show_memory:\n",
      "   842                                                       free_GB_after = get_free_memory(train.device)\n",
      "   843                                                       print(f'empty_cache(): {free_GB_fin-free_GB_after:.2f}GB deallocated')\n",
      "   844                                                       print(f'final: {free_GB_after:.2f}GB free')"
     ]
    }
   ],
   "source": [
    "filename = f'timings/{model_time.train.algoname}.txt'\n",
    "%lprun -f model_time.solve -T $filename model_time.solve(do_print=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
