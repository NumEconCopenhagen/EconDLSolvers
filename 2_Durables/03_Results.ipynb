{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Imports](#toc1_)    \n",
    "- 2. [Load Data           ](#toc2_)    \n",
    "  - 2.1. [Hyperparameters](#toc2_1_)    \n",
    "- 3. [Life cycle income](#toc3_)    \n",
    "- 4. [Convergence](#toc4_)    \n",
    "- 5. [Life-cycle profiles](#toc5_)    \n",
    "- 6. [Transfer](#toc6_)    \n",
    "- 7. [Speed of Convergence           ](#toc7_)    \n",
    "  - 7.1. [With DP](#toc7_1_)    \n",
    "  - 7.2. [New LR](#toc7_2_)    \n",
    "  - 7.3. [Without DP](#toc7_3_)    \n",
    "- 8. [(Consumption) Euler Errors](#toc8_)    \n",
    "- 9. [Table](#toc9_)    \n",
    "  - 9.1. [DP](#toc9_1_)    \n",
    "  - 9.2. [Full](#toc9_2_)    \n",
    "- 10. [Policy functions](#toc10_)    \n",
    "  - 10.1. [1D](#toc10_1_)    \n",
    "    - 10.1.1. [Chose where to plot policy](#toc10_1_1_)    \n",
    "    - 10.1.2. [Generate policies in levels](#toc10_1_2_)    \n",
    "    - 10.1.3. [Plot](#toc10_1_3_)    \n",
    "  - 10.2. [8D](#toc10_2_)    \n",
    "    - 10.2.1. [Choose where to plot policy](#toc10_2_1_)    \n",
    "    - 10.2.2. [Get policy in levels](#toc10_2_2_)    \n",
    "    - 10.2.3. [Plot policy](#toc10_2_3_)    \n",
    "- 11. [More on convergence](#toc11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE' # without this python may crash when plotting from matplotlib\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams.update({\"axes.grid\":True,\"grid.color\": \"black\",\"grid.alpha\":\"0.25\",\"grid.linestyle\": \"--\"})\n",
    "plt.rcParams.update({'font.size':14})\n",
    "plt.rcParams.update({'font.family':'serif'})\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "from plot_funcs import load_all, compute_transfer, convergence_plot, transfer_plot, train_specs\n",
    "from DurablesModel import DurablesModelClass\n",
    "from model_funcs import compute_d_and_c_from_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EconDLSolvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Load Data](#toc2_)            [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_load = '../output/'\n",
    "folder = '../output/results'\n",
    "algonames = ['DeepSimulate','DeepFOC','DeepVPD']\n",
    "Ds = [1,2,3,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "algolabels = {\n",
    "    'DeepSimulate':'DeepSimulate',\n",
    "    'DeepFOC':'DeepFOC',\n",
    "    'DeepVPD':'DeepVPD+',\n",
    "    'DeepVPD-FOC':'DeepVPD++',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_all(folder_load,'DurablesModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change baseline:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for D in [1,2,3]:\n",
    "#     Dstr = f'{D}D'\n",
    "#     models[('DeepVPD',Dstr,'fixedLR')] = models[('DeepVPD',Dstr)]\n",
    "#     models[('DeepVPD',Dstr)] = models[('DeepVPD',Dstr,'altLR')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. <a id='toc2_1_'></a>[Hyperparameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_display = False\n",
    "for D in Ds:\n",
    "    if do_display: print(f'D = {D}')\n",
    "    models_ = {k:v for k,v in models.items() if int(k[1][0]) == D and len(k) == 2}\n",
    "    train_specs(models_,do_display=do_display,folder=folder,filename=f'DurablesModel_train_specs_{D}D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Life cycle income](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[('DP','1D')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6,3))\n",
    "\n",
    "ax.plot(model.par.kappa)\n",
    "\n",
    "ax.set_xlabel('period $t$')\n",
    "ax.set_ylabel('$\\\\kappa_t$')\n",
    "\n",
    "filepath = f\"{folder}/DurablesModel_kappa.svg\"\n",
    "plt.savefig(filepath, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id='toc4_'></a>[Convergence](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in Ds:\n",
    "    #for algoname,extra in [(algoname,None) for algoname in algonames] + [('DeepVPD','fixedLR')]:\n",
    "    for algoname,extra in [(algoname,None) for algoname in algonames]:\n",
    "        \n",
    "        if D == 8 and not extra is None: continue \n",
    "        \n",
    "        print(f'D = {D}, algoname = {algoname}',end='')\n",
    "        if extra is not None: \n",
    "            print(f' {extra}',end='')\n",
    "        else:\n",
    "            print('')\n",
    "\n",
    "        model = models[(algoname,f'{D}D')] if extra is None else models[(algoname,f'{D}D',extra)]\n",
    "        postfix = f'_DurablesModel_{algoname}_{D}D'\n",
    "        if extra is not None: postfix += f'_{extra}'\n",
    "\n",
    "        EconDLSolvers.convergence_plot(model,\n",
    "                         y_fac=10_000,ylabel='transfer, bp. of initial cash-on-hand',\n",
    "                         folder=folder,postfix=postfix,close_fig=False)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in [1,2,8]:\n",
    "        \n",
    "    model = models[('DeepFOC',f'{D}D')]\n",
    "    k_max = model.info['iter']\n",
    "\n",
    "    x = [model.info[('k_time',k)]/60 for k in range(k_max) if ('policy_loss',k) in model.info and model.info[('k_time',k)]/60 > 1]    \n",
    "    y = [model.info[('policy_loss',k)] for k in range(k_max) if ('policy_loss',k) in model.info and model.info[('k_time',k)]/60 > 1]\n",
    "\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "    best_yi = np.inf\n",
    "    for xi,yi in zip(x,y):\n",
    "        if yi < best_yi:\n",
    "            x_.append(xi)\n",
    "            y_.append(yi)\n",
    "            best_yi = yi\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,4))\n",
    "    # ax.set_title(f'DeepFOC - {D}D')\n",
    "    ax.plot(x_,y_,'-o',ms='2',color=colors[0])\n",
    "    ax.set_xlabel('time (m)')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'{folder}/DurablesModel_DeepFOC_{D}D_policy_loss.svg')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id='toc5_'></a>[Life-cycle profiles](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in [1,2,3]:\n",
    "    for algoname in ['DP'] + algonames:\n",
    "\n",
    "        if algoname == 'DP' and D == 3: continue\n",
    "\n",
    "        print(algoname,D)\n",
    "\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "        ax = fig.add_subplot(1,2,1)\n",
    "        if not algoname == 'DP':\n",
    "            label = algolabels[algoname]\n",
    "            ax.plot(np.mean(models[(f'{algoname}',f'{D}D')].sim.states[:,:,0],axis=1),label=label,color=colors[0], lw=2)\n",
    "            if D <= 2:\n",
    "                ax.plot(np.mean(models[('DP',f'{D}D','fine')].sim.states[:,:,0],axis=1),label='NEGM+',color=colors[0], lw=2,ls='--')\n",
    "            else:\n",
    "                ax.plot(np.mean(models[('DP',f'{D}D','rough')].sim.states[:,:,0],axis=1),label='NEGM-',color=colors[0], lw=2,ls='--')\n",
    "        else:\n",
    "            ax.plot(np.mean(models[('DP',f'{D}D')].sim.states[:,:,0],axis=1),label='NEGM',color=colors[0], lw=2,ls='-')\n",
    "            ax.plot(np.mean(models[('DP',f'{D}D','rough')].sim.states[:,:,0],axis=1),label='NEGM-',color=colors[0], lw=2,ls='--')\n",
    "            ax.plot(np.mean(models[('DP',f'{D}D','fine')].sim.states[:,:,0],axis=1),label='NEGM+',color=colors[0], lw=2,ls='-.')\n",
    "        \n",
    "        ax.axvline(x=model.par.T_retired, lw=2,color='black', linestyle='--')\n",
    "        ax.set_xlabel('period, $t$')\n",
    "        ax.set_title('cash-on-hand')\n",
    "        ax.legend()\n",
    "\n",
    "        ax = fig.add_subplot(1,2,2)\n",
    "        if not algoname == 'DP':\n",
    "            for k in range(D):\n",
    "                ax.plot(np.mean(models[(f'{algoname}',f'{D}D')].sim.states[:,:,2+k],axis=1),label=f'durable {1+k}',color=colors[k], lw=2)\n",
    "                if D <= 2:\n",
    "                    ax.plot(np.mean(models[('DP',f'{D}D')].sim.states[:,:,2+k],axis=1),color=colors[k], lw=2,ls='--')\n",
    "                else:               \n",
    "                    ax.plot(np.mean(models[('DP',f'{D}D','rough')].sim.states[:,:,2+k],axis=1),color=colors[k], lw=2,ls='--')\n",
    "        else:\n",
    "            for k in range(D):\n",
    "                ax.plot(np.mean(models[('DP',f'{D}D')].sim.states[:,:,2+k],axis=1),label=f'durable {1+k}',color=colors[k], lw=2,ls='-')\n",
    "                ax.plot(np.mean(models[('DP',f'{D}D','rough')].sim.states[:,:,2+k],axis=1),color=colors[k], lw=2,ls='--')\n",
    "                ax.plot(np.mean(models[('DP',f'{D}D','fine')].sim.states[:,:,2+k],axis=1),color=colors[k], lw=2,ls='-.')\n",
    "                \n",
    "        ax.axvline(x=model.par.T_retired,lw=2, label='retirement',color='black', linestyle='--')\n",
    "        ax.set_xlabel('period, $t$')\n",
    "        \n",
    "        if D == 1:\n",
    "            ax.set_title('durable')\n",
    "        else:\n",
    "            ax.set_title('durables')\n",
    "            ax.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f'{folder}/DurablesModel_lcp_{D}D_{algoname}.svg')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basenames = ['DeepSimulate']\n",
    "\n",
    "for basename in basenames:\n",
    "    for D in [1,2,3,8]:\n",
    "        for algoname in algonames: \n",
    "\n",
    "            if algoname == basename: continue\n",
    "\n",
    "            label = algolabels[algoname]\n",
    "            print(f'{algoname}, {D}D [basename: {basename}]')\n",
    "\n",
    "            fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "            ax = fig.add_subplot(2,1,1)\n",
    "            ax.plot(np.mean(models[(f'{algoname}',f'{D}D')].sim.states[:,:,0],axis=1),label=label,color=colors[0],linewidth=2)\n",
    "            ax.plot(np.mean(models[(f'{basename}',f'{D}D')].sim.states[:,:,0],axis=1),label=basename,color=colors[0],linewidth=2,ls='--')\n",
    "            ax.axvline(x=model.par.T_retired, linewidth=2,color='black', linestyle='--')\n",
    "            \n",
    "            ax.set_ylim([0.9,2.5])\n",
    "            ax.set_xlabel('period, $t$')\n",
    "            ax.set_title('cash-on-hand')\n",
    "            ax.legend()\n",
    "\n",
    "            ax = fig.add_subplot(2,1,2)\n",
    "            for k in range(D):\n",
    "                delta = models[(f'{algoname}',f'{D}D')].par.delta[k]\n",
    "                ax.plot(np.mean(models[(f'{algoname}',f'{D}D')].sim.states[:,:,2+k],axis=1),label=f'{1+k}',color=colors[k], linewidth=2)\n",
    "                ax.plot(np.mean(models[(f'{basename}',f'{D}D')].sim.states[:,:,2+k],axis=1),color=colors[k], linewidth=2,ls='--')\n",
    "            \n",
    "            ax.axvline(x=model.par.T_retired,linewidth=2,color='black', linestyle='--')\n",
    "            if D < 3:\n",
    "                ax.set_ylim([0,1.0])\n",
    "            elif D == 3:\n",
    "                ax.set_ylim([0,0.7])\n",
    "            elif D == 8:\n",
    "                ax.set_ylim([0,0.3])\n",
    "            ax.set_xlabel('period, $t$')\n",
    "            ax.set_title('durables')\n",
    "            ax.legend(ncols=5,fontsize=12)\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            filepath = f\"{folder}/DurablesModel_lcp_{D}D_{algoname}_base{basename}.svg\"\n",
    "            fig.savefig(filepath)\n",
    "\n",
    "            if D <= 3:\n",
    "                plt.close(fig)\n",
    "                display(HTML(f'<a href=\"{filepath}\">{filepath}</a>'))\n",
    "            else:\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basenames = ['DeepSimulate']\n",
    "\n",
    "for basename in basenames:\n",
    "    for D in [1,2,3,8]:\n",
    "        for algoname in algonames: \n",
    "\n",
    "            if algoname == basename: continue\n",
    "\n",
    "            label = algolabels[algoname]\n",
    "            print(f'{algoname}, {D}D [basename: {basename}]')\n",
    "\n",
    "            fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "            ax = fig.add_subplot(2,1,1)\n",
    "            m_base = models[(f'{basename}',f'{D}D')].sim.states[:,:,0]\n",
    "            m_algo = models[(f'{algoname}',f'{D}D')].sim.states[:,:,0]\n",
    "            y = [np.corrcoef(m_base[t],m_algo[t])[0,1] for t in range(model.par.T)]\n",
    "\n",
    "            ax.plot(y,label=label,color=colors[0],linewidth=2)\n",
    "            ax.axvline(x=model.par.T_retired, linewidth=2,color='black', linestyle='--')\n",
    "            \n",
    "            ax.set_ylim([0.8,1.01])\n",
    "            ax.set_xlabel('period, $t$')\n",
    "            ax.set_title('cash-on-hand')\n",
    "            ax.legend()\n",
    "\n",
    "            ax = fig.add_subplot(2,1,2)\n",
    "            for k in range(D):\n",
    "                d_base = models[(f'{basename}',f'{D}D')].sim.states[:,:,2+k]\n",
    "                d_algo = models[(f'{algoname}',f'{D}D')].sim.states[:,:,2+k]   \n",
    "                y = [np.corrcoef(d_base[t],d_algo[t])[0,1] for t in range(model.par.T)]             \n",
    "                ax.plot(y,label=f'{1+k}',color=colors[k], linewidth=2)\n",
    "            \n",
    "            ax.axvline(x=model.par.T_retired,linewidth=2,color='black', linestyle='--')\n",
    "            ax.set_ylim([0.8,1.01])\n",
    "            ax.set_xlabel('period, $t$')\n",
    "            ax.set_title('durables')\n",
    "            ax.legend(ncols=5,fontsize=12)\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            filepath = f\"{folder}/DurablesModel_lcp_corr_{D}D_{algoname}_base{basename}.svg\"\n",
    "            fig.savefig(filepath)\n",
    "\n",
    "            if D <= 2:\n",
    "                plt.close(fig)\n",
    "                display(HTML(f'<a href=\"{filepath}\">{filepath}</a>'))\n",
    "            else:\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a id='toc6_'></a>[Transfer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = [1]\n",
    "for D in Ds:\n",
    "    transfer_plot('DurablesModel',models,algonames,D,folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a id='toc7_'></a>[Speed of Convergence](#toc4_2_)            [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. <a id='toc7_1_'></a>[With DP](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = [0.1,1000]\n",
    "ylim = [-1000,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in [1,2,3]:\n",
    "    \n",
    "    for DPstr in ['rough','','fine']:\n",
    "\n",
    "        Dstr = f'{D}D'\n",
    "        postfix = f'_{Dstr}'\n",
    "        print(Dstr,DPstr)\n",
    "\n",
    "        if DPstr == '': \n",
    "            if  ('DP',Dstr) not in models: continue\n",
    "            DP = models[('DP',Dstr)]\n",
    "        else:\n",
    "            if  ('DP',Dstr,DPstr) not in models: continue\n",
    "            DP = models[('DP',Dstr,DPstr)]\n",
    "\n",
    "        if DPstr == 'fine':\n",
    "            DP_name = '+'\n",
    "        elif DPstr == 'rough':\n",
    "            DP_name = '-'\n",
    "        else:\n",
    "            DP_name = ''\n",
    "\n",
    "        if not DPstr == '': postfix += f'_{DPstr}'\n",
    "\n",
    "        specs = {(algoname,Dstr):algolabels[algoname] for algoname in algonames}\n",
    "\n",
    "        convergence_plot('DurablesModel',models,specs,DP=DP,do_transfer=True,DP_name=f'NEGM{DP_name}',\n",
    "                            xlim=xlim,ylim=ylim,folder=folder,postfix=postfix)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. <a id='toc7_2_'></a>[New LR](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for D in [1,2,3]:\n",
    "    \n",
    "#     for DPstr in ['rough','','fine']:\n",
    "\n",
    "#         Dstr = f'{D}D'\n",
    "#         postfix = f'_{Dstr}'\n",
    "#         print(Dstr,DPstr)\n",
    "\n",
    "#         if DPstr == '': \n",
    "#             if  ('DP',Dstr) not in models: continue\n",
    "#             DP = models[('DP',Dstr)]\n",
    "#         else:\n",
    "#             if  ('DP',Dstr,DPstr) not in models: continue\n",
    "#             DP = models[('DP',Dstr,DPstr)]\n",
    "\n",
    "#         if DPstr == 'fine':\n",
    "#             DP_name = '+'\n",
    "#         elif DPstr == 'rough':\n",
    "#             DP_name = '-'\n",
    "#         else:\n",
    "#             DP_name = ''\n",
    "\n",
    "#         if not DPstr == '': postfix += f'_{DPstr}'\n",
    "\n",
    "#         postfix += f'_lr'\n",
    "#         specs = {}\n",
    "#         specs[('DeepVPD',Dstr)] = f'DeepVPD (adjusted lr)'\n",
    "#         specs[('DeepVPD',Dstr,'fixedLR')] = f'DeepVPD (fixed lr)'\n",
    "\n",
    "#         convergence_plot('DurablesModel',models,specs,DP=DP,do_transfer=True,DP_name=f'NEGM{DP_name}',\n",
    "#                             xlim=xlim,ylim=ylim,folder=folder,postfix=postfix)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. <a id='toc7_3_'></a>[Without DP](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = [8]\n",
    "ylim = [-50,-44]\n",
    "for D in Ds:\n",
    "    \n",
    "    Dstr = f'{D}D'\n",
    "    print(Dstr)\n",
    "\n",
    "    specs = {(algoname,Dstr):algolabels[algoname] for algoname in algonames}\n",
    "\n",
    "    convergence_plot('DurablesModel',models,specs,DP=None,do_transfer=False,DP_name='NEGM',\n",
    "                     xlim=xlim,ylim=ylim,\n",
    "                     folder=folder,postfix=f'_{Dstr}')\n",
    "    \n",
    "    convergence_plot('DurablesModel',models,specs,DP=None,do_transfer=False,\n",
    "                     xlim=xlim,ylim=[-45.50,-45.40],\n",
    "                     folder=folder,postfix=f'_{Dstr}_zoom')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepVPD-FOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 8\n",
    "# Dstr = f'{D}D'\n",
    "# specs = {}\n",
    "# specs[('DeepExplore',Dstr)] = 'DeepExplore'\n",
    "# specs[('DeepVPD',Dstr)] = algolabels['DeepVPD']\n",
    "# specs[('DeepVPD',Dstr,'FOC')] = algolabels['DeepVPD-FOC']\n",
    "# ylim = [-50,-44]\n",
    "\n",
    "# convergence_plot('DurablesModel',models,specs,DP=None,do_transfer=False,DP_name='NEGM',\n",
    "#                     xlim=xlim,ylim=ylim,\n",
    "#                     folder=folder,postfix=f'_{Dstr}_DeepVPD_FOC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. <a id='toc8_'></a>[(Consumption) Euler Errors](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_euler_DP(key,model):\n",
    "\n",
    "    par = model.par\n",
    "    savings_indicator = (model.sim.states_pd[:model.par.T_retired,:,0] > 1e-4)\n",
    "    euler_error = model.sim.euler_error[:par.T_retired]\n",
    "    euler_error = euler_error[savings_indicator]\n",
    "    J = np.isclose(np.abs(euler_error),0.0)\n",
    "    model.info['euler_errors'] = np.log10(np.abs(euler_error[~J]))\n",
    "    mean_euler_error = model.info['mean_euler_error'] = np.mean(model.info['euler_errors'])\n",
    "    print(f'{str(key):30s} = {mean_euler_error:.2f} [{np.mean(J):.4f} share of euler errors are zero]')\n",
    "    \n",
    "for key,model in models.items():\n",
    "    compute_mean_euler_DP(key,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = [1,2,3,8]\n",
    "do_display = True\n",
    "algonames = ['DeepSimulate','DeepFOC','DeepVPD']\n",
    "\n",
    "for D in Ds:\n",
    "    print(f'{D = }')\n",
    "    for i,algoname in enumerate(algonames):\n",
    "\n",
    "        if D <= 3:\n",
    "            DP = models[('DP',f'{D}D','fine')] if D < 3 else models[('DP',f'{D}D','rough')]\n",
    "            _ = DP.info['euler_errors']\n",
    "        else:\n",
    "            DP = None\n",
    "\n",
    "        label = algolabels[algoname]\n",
    "\n",
    "        fig,ax = plt.subplots(1,1,figsize=(9,6))\n",
    "\n",
    "        if not DP is None:\n",
    "            ax.hist(DP.info['euler_errors'],bins=100,alpha=0.5,color='grey',density=True,label='EGM')\n",
    "            ax.axvline(x=DP.info['mean_euler_error'],color='grey',linestyle='--',label=f'EGM, mean')   \n",
    "\n",
    "        model = models[(f'{algoname}',f'{D}D')]\n",
    "        ax.hist(model.info['euler_errors'],bins=100,alpha=0.5,color=colors[i],density=True,label=label)\n",
    "        ax.axvline(x=model.info['mean_euler_error'],color=colors[i],linestyle='--',label=f'{label}, mean')\n",
    "     \n",
    "        ax.set_xlabel('Euler error')\n",
    "        ax.set_ylabel('density')\n",
    "        ax.set_xlim([-6,0])\n",
    "        ax.set_ylim([0,1.4])\n",
    "        ax.legend(loc='upper left')\n",
    "        \n",
    "        filepath = f\"{folder}/DurablesModel_euler_error_{D}D_{algoname}.svg\"\n",
    "        fig.savefig(filepath,bbox_inches='tight')\n",
    "\n",
    "        if do_display:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "            display(HTML(f'<a href=\"{filepath}\">{filepath}</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = [8]\n",
    "do_display = True\n",
    "algonames = ['DeepSimulate','DeepFOC','DeepVPD']\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(9,6))\n",
    "for i,algoname in enumerate(algonames):\n",
    "\n",
    "    model = models[(f'{algoname}',f'{D}D')]\n",
    "    label = algolabels[algoname]\n",
    "    ax.hist(model.info['euler_errors'],bins=100,alpha=0.5,color=colors[i],density=True,label=label)\n",
    "    ax.axvline(x=model.info['mean_euler_error'],color=colors[i],linestyle='--',label=f'{label}, mean')\n",
    "    \n",
    "ax.set_xlabel('Euler error')\n",
    "ax.set_ylabel('density')\n",
    "ax.set_xlim([-6,0])\n",
    "ax.set_ylim([0,1.4])\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "filepath = f\"{folder}/DurablesModel_euler_error_{D}D.svg\"\n",
    "fig.savefig(filepath,bbox_inches='tight')\n",
    "\n",
    "if do_display:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(fig)\n",
    "    display(HTML(f'<a href=\"{filepath}\">{filepath}</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. <a id='toc9_'></a>[Table](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. <a id='toc9_1_'></a>[DP](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_DP(models,labels):\n",
    "\n",
    "    # a. define column and row titles\n",
    "    columns = labels    \n",
    "    rows = [\n",
    "        '$R$', \n",
    "        'Euler-error', \n",
    "        '',\n",
    "        'Time (m)', \n",
    "        '',\n",
    "        'Nn', \n",
    "        'Nm', \n",
    "        'Np', \n",
    "        'Nm-pd', \n",
    "        'Nm (keep)', \n",
    "        '',\n",
    "        'GB', \n",
    "    ]\n",
    "\n",
    "    # b. create with NaN values\n",
    "    df = pd.DataFrame(index=rows,columns=columns).fillna('-')\n",
    "    for col in columns:\n",
    "        df.loc['',col] = ''\n",
    "\n",
    "    # c. fill in values\n",
    "    for model,label in zip(models,labels):\n",
    "        df.loc['$R$',label] = f\"{model.sim.R:.4f}\"\n",
    "        if 'mean_euler_error' in model.info:\n",
    "            df.loc['Euler-error',label] = f\"{model.info['mean_euler_error']:.2f}\"\n",
    "        df.loc['Time (m)',label] = f\"{model.info['time']/60:.2f}\"\n",
    "        for key in ['Nn','Nm','Np','Nm_pd','Nm_keep']:\n",
    "            if key == 'Nm_keep':\n",
    "                df.loc['Nm (keep)',label] = model.egm.Nm_keep\n",
    "            elif key == 'Nm_pd':\n",
    "                df.loc['Nm-pd',label] = model.egm.Nm_pd\n",
    "            else:\n",
    "                df.loc[key,label] = model.egm.__dict__[key]\n",
    "        df.loc['GB',label] = f\"{model.info['memory_usage']:.2f}\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. select\n",
    "models_DP = []\n",
    "labels = []\n",
    "for D in [1,2,3]:\n",
    "\n",
    "    models_DP.append(models[('DP',f'{D}D','rough')])\n",
    "    labels.append(f'{D}D-')    \n",
    "\n",
    "    try:\n",
    "        models_DP.append(models[('DP',f'{D}D')])\n",
    "        labels.append(f'{D}D')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        models_DP.append(models[('DP',f'{D}D','fine')])\n",
    "        labels.append(f'{D}D+')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# b. table\n",
    "df = create_table_DP(models_DP,labels)\n",
    "display(df)\n",
    "\n",
    "# c.save\n",
    "filename = f'{folder}/DurablesModel_table_DP.tex'\n",
    "df.style.to_latex(filename,hrules=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. <a id='toc9_2_'></a>[Full](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(models,labels,DP=None,DP_name='NEGM'):\n",
    "\n",
    "    # define column and row titles\n",
    "    columns = [DP_name] + labels\n",
    "    \n",
    "    rows = [\n",
    "        'Life-time reward, $R$', \n",
    "        'Transfer (bp.)', \n",
    "        'Euler-error', \n",
    "        '',\n",
    "        'Total time (m)', \n",
    "        '\\,\\,\\,update NN', \n",
    "        '\\,\\,\\,simulation: training sample', \n",
    "        '\\,\\,\\,simulation: out-of-sample $R$', \n",
    "        'Iterations', \n",
    "        'Avg. policy epochs', \n",
    "        'Avg. value epochs',\n",
    "    ]\n",
    "\n",
    "    # create with NaN values\n",
    "    df = pd.DataFrame(index=rows,columns=columns).fillna('-')  # using '-' to represent missing df for display purposes\n",
    "    for col in columns: df.loc['',col] = ''\n",
    "\n",
    "    do_DP = DP is not None\n",
    "\n",
    "    if do_DP: df.loc['Life-time reward, $R$', DP_name] = f'{DP.sim.R:.4f}'\n",
    "    for model,label in zip(models,labels):\n",
    "       df.loc['Life-time reward, $R$', label] = f\"{model.sim.R:.4f}\"\n",
    "\n",
    "    if do_DP:\n",
    "\n",
    "        df.loc['Transfer (bp.)', DP_name] = 0\n",
    "        for model,label in zip(models,labels):\n",
    "\n",
    "            model = model\n",
    "            \n",
    "            R = model.sim.R\n",
    "            R_transfer = deepcopy(DP.sim.R_transfer)\n",
    "            transfer = compute_transfer(R_transfer,DP.egm.transfer_grid,R,do_extrap=False)\n",
    "            transfer_mean = transfer\n",
    "            \n",
    "            if not np.isnan(transfer_mean):\n",
    "                df.loc['Transfer (bp.)', label] = f\"{100**2*transfer_mean:.0f}\"\n",
    "            else:\n",
    "                df.loc['Transfer (bp.)', label] = '-'\n",
    "\n",
    "    if do_DP: df.loc['Euler-error', DP_name] = f\"{DP.info['mean_euler_error']:.2f}\"\n",
    "    for model,label in zip(models,labels):\n",
    "        model = model\n",
    "        df.loc['Euler-error', label] = f\"{model.info['mean_euler_error']:.2f}\"\n",
    "    \n",
    "    if do_DP: df.loc['Total time (m)', DP_name] = f\"{DP.info['time']/60:.2f}\"\n",
    "    for model,label in zip(models,labels):\n",
    "        df.loc['Total time (m)', label] = f\"{model.info['time']/60:.2f}\"\n",
    "\n",
    "    df.loc['\\,\\,\\,update NN',DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        time_rel = model.info['time.update_NN'] / model.info['time']\n",
    "        df.loc['\\,\\,\\,update NN', label] = f\"{100*time_rel:.1f}\\%\"\n",
    "\n",
    "    df.loc['\\,\\,\\,simulation: training sample',DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        time_rel = model.info['time._simulate_training_sample'] / model.info['time']\n",
    "        df.loc['\\,\\,\\,simulation: training sample', label] = f\"{100*time_rel:.1f}\\%\"\n",
    "\n",
    "    df.loc['\\,\\,\\,simulation: out-of-sample $R$',DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        time_rel = model.info['time.simulate_R'] / model.info['time']\n",
    "        df.loc['\\,\\,\\,simulation: out-of-sample $R$', label] = f\"{100*time_rel:.1f}\\%\"\n",
    "\n",
    "    df.loc['Iterations', DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        df.loc['Iterations', label] = model.info['iter']\n",
    "\n",
    "    df.loc['Avg. policy epochs', DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        df.loc['Avg. policy epochs', label] = f\"{model.info[('policy_epochs','mean')]:.1f}\"\n",
    "\n",
    "    df.loc['Avg. value epochs', DP_name] = '-'\n",
    "    for model,label in zip(models,labels):\n",
    "        df.loc['Avg. value epochs', label] = f\"{model.info[('value_epochs','mean')]:.1f}\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for D in [1,2,3,8]:\n",
    "\n",
    "    print(f'{D = }')\n",
    "    if D == 1:\n",
    "        DP = models[('DP',f'{D}D','fine')]\n",
    "        DP_name = 'NEGM+'\n",
    "    elif D == 2:\n",
    "        DP = models[('DP',f'{D}D','fine')]\n",
    "        DP_name = 'NEGM+'\n",
    "    elif D == 3:\n",
    "        DP = models[('DP',f'{D}D','rough')]\n",
    "        DP_name = 'NEGM-'\n",
    "    else:\n",
    "        DP = None\n",
    "        DP_name = 'NEGM'\n",
    "\n",
    "    models_ = [models[(algoname,f'{D}D')] for algoname in algonames]\n",
    "    labels = [algolabels[algoname] for algoname in algonames]\n",
    "\n",
    "    df = create_table(models_,labels,DP=DP,DP_name=DP_name)\n",
    "    display(df)\n",
    "\n",
    "    filename = f'{folder}/DurablesModel_table_{D}D.tex'\n",
    "    df.style.to_latex(filename,hrules=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. <a id='toc10_'></a>[Policy functions](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 10.1. <a id='toc10_1_'></a>[1D](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.1. <a id='toc10_1_1_'></a>[Chose where to plot policy](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get means at t\n",
    "t = 5\n",
    "\n",
    "means = np.mean(models[('DeepSimulate','1D')].sim.states,axis=1)\n",
    "\n",
    "# find index in gid closest to mean of p and n\n",
    "p_index = np.argmin(np.abs(models[('DP','1D')].egm.p_grid - means[t,1]))\n",
    "n_index = np.argmin(np.abs(models[('DP','1D')].egm.n_grid - means[t,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.2. <a id='toc10_1_2_'></a>[Generate policies in levels](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DL POLICY FUNCTION AT CHOSEN POINTS\n",
    "\n",
    "algoname = 'DeepSimulate'\n",
    "\n",
    "# create model to get policy function\n",
    "# par_dict = {'T':models[(algoname,'1D')].par.T,'D':models[(algoname,'1D')].par.D,'KKT':algoname=='DeepFOC','full':True}\n",
    "par_dict = {'T':models[(algoname,'1D')].par.T,'D':models[(algoname,'1D')].par.D,'KKT':algoname=='DeepFOC','full':True}\n",
    "train_dict = {'Nneurons_policy':models[(algoname,'1D')].train.Nneurons_policy}\n",
    "model = DurablesModelClass(algoname = algoname,par=par_dict,train=train_dict,device='cpu')\n",
    "model.par.tau = models[(algoname,'1D')].par.tau\n",
    "\n",
    "# load weights\n",
    "model.policy_NN.load_state_dict(models[(algoname,'1D')].policy_NN)\n",
    "\n",
    "# create state-tensor to compute policy on\n",
    "state_tensor = torch.zeros((models[('DP','1D')].egm.Nm,model.par.Nstates+model.par.T),requires_grad=False)\n",
    "state_tensor[:,0] = torch.tensor(models[('DP','1D')].egm.m_grid,requires_grad=False)\n",
    "state_tensor[:,1] = models[('DP','1D')].egm.p_grid[p_index]\n",
    "state_tensor[:,2] = models[('DP','1D')].egm.n_grid[n_index]\n",
    "state_tensor[:,2+t] = 1\n",
    "\n",
    "# compute policy at these points\n",
    "policy = model.policy_NN(state_tensor)\n",
    "\n",
    "#  convert policy to levels\n",
    "c,d,a = compute_d_and_c_from_action(model.par,state_tensor,policy)\n",
    "c = c.detach().numpy()\n",
    "d = d.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_consume_all(tau,m,epsilon):\n",
    "\t\"\"\" Computation maximum investment level if the consumer spend all cash-on-hand except for epsilon \"\"\"\n",
    "\n",
    "\tif tau == 0.0:\n",
    "\t\n",
    "\t\tDelta_max = m - epsilon # if no adjustment cost problem is linear\n",
    "\t\n",
    "\telse:\n",
    "\n",
    "\t\ta = (-tau)\n",
    "\t\tb = -1\n",
    "\t\tc = m - epsilon\n",
    "\t\tdenominator = 2*a\n",
    "\t\tnumerator = (-b - (b**2-4*a*c)**(1/2))\n",
    "\t\tDelta_max = numerator/denominator\n",
    "\n",
    "\treturn Delta_max\n",
    "def adj_cost(par,Delta):\n",
    "\t\"\"\" Adjustment cost \"\"\"\n",
    "\n",
    "\treturn par.nu * (Delta)**2\n",
    "\n",
    "def compute_d_and_c_from_action_DP(par,state,action,eps=None):\n",
    "\t\"\"\" Compute c,d,m_pd from state and action\"\"\"\n",
    "\n",
    "\t# a. make array for d\n",
    "\tarray_shape =  state.shape[:-1] + (par.D,)\n",
    "\tif type(state) is np.ndarray:\n",
    "\t\tarray_shape =  state.shape[:-1] + (par.D,)\n",
    "\t\td_array = np.zeros(array_shape)\n",
    "\telse:\n",
    "\t\td_array = torch.zeros(array_shape,dtype=state.dtype,device=state.device)\n",
    "\n",
    "\t# b. loop over durables to get durable choices\n",
    "\tmbar = 0.0 # initialize\n",
    "\tfor i_d in range(par.D):\n",
    "\n",
    "\t\t# i. compute bounds\n",
    "\t\td_low = 0.0\n",
    "\t\tif par.nonnegative_investment:\n",
    "\t\t\td_low = state[...,2+i_d]\n",
    "\t\t\n",
    "\t\tif i_d == 0:\n",
    "\t\t\tmbar = state[...,0]\n",
    "\n",
    "\t\td_high = state[...,2+i_d] + d_consume_all(par.tau,mbar,0.0)\n",
    "\n",
    "\t\t# ii. add noise to action if needed\n",
    "\t\tif eps is None:\n",
    "\t\t\taction_d = action[...,1+i_d]\n",
    "\t\telse:\n",
    "\t\t\tif type(state) is np.ndarray:\n",
    "\t\t\t\taction_d = np.clip(action[...,1+i_d]+eps[...,1+i_d],0,0.9999)\n",
    "\t\t\telse:\n",
    "\t\t\t\taction_d = torch.clamp(action[...,1+i_d]+eps[...,1+i_d],0,0.9999)\n",
    "\t\t\n",
    "\t\t# iii. compute durable consumption\n",
    "\t\td = d_low+(d_high-d_low)*action_d\n",
    "\n",
    "\t\t# iv. store durable consumption\n",
    "\t\td_array[...,i_d] = d\n",
    "\n",
    "\t\t# v. compute wealth after durable consumption\n",
    "\t\tDelta_d = d - state[...,2+i_d]\n",
    "\t\tmbar = mbar - Delta_d - adj_cost(par,Delta_d)\n",
    "\t\n",
    "\t# c. compute consumption\n",
    "\tif eps is None:\n",
    "\t\taction_c = action[...,0]\n",
    "\telse:\n",
    "\t\tif type(state) is np.ndarray:\n",
    "\t\t\taction_c = np.clip(action[...,0] + eps[...,0],0,0.9999)\n",
    "\t\telse:\n",
    "\t\t\taction_c = torch.clamp(action[...,0] + eps[...,0],0,0.9999)\n",
    "\n",
    "\tc = mbar*(1-action_c)\n",
    "\n",
    "\t# e. compute a from c\n",
    "\tm_pd = mbar - c\n",
    "\n",
    "\treturn c,d_array,m_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DP POLICY FUNCTION AT CHOSEN POINTS\n",
    "\n",
    "# get policy functions\n",
    "a_policy = models[('DP','1D')].egm.sol_m_pd_fac[t,p_index,n_index]\n",
    "d_policy = models[('DP','1D')].egm.sol_d1_fac[t,p_index,n_index]\n",
    "\n",
    "# map policies into same structure as NN_policies\n",
    "actions = np.zeros((models[('DP','1D')].egm.Nm,2))\n",
    "actions[:,0] = a_policy\n",
    "actions[:,1] = d_policy\n",
    "state_np = state_tensor.numpy()\n",
    "\n",
    "# get policies in levels\n",
    "models[('DP','1D')].par.nu = models[('DP','1D')].par.tau \n",
    "c_dp,d_dp,m_pd_dp = compute_d_and_c_from_action_DP(models[('DP','1D')].par,state_np,actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1.3. <a id='toc10_1_3_'></a>[Plot](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(9,6))\n",
    "\n",
    "# plot policy\n",
    "ax.plot(models[('DP','1D')].egm.m_grid,c,label='sell',color=colors[0],lw=2)\n",
    "ax.plot(models[('DP','1D')].egm.m_grid,c_dp,label='sell',color=colors[0],lw=2,ls='--')\n",
    "\n",
    "ax.set_xlabel('cash-on-hand, $m$')\n",
    "ax.set_ylabel('consumption, $c$')\n",
    "ax.set_xlim([0,3])\n",
    "ax.set_ylim([0.0,1.2])\n",
    "\n",
    "filepath = f\"{folder}/DurablesModel_c_policy_DeepSimulate_D1.svg\"\n",
    "fig.savefig(filepath,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(9,6))\n",
    "\n",
    "# plot policy\n",
    "ax.plot(models[('DP','1D')].egm.m_grid,d,color=colors[0],lw=2, label='DL')\n",
    "ax.plot(models[('DP','1D')].egm.m_grid,d_dp,label='DP',color=colors[0],lw=2,ls='--')\n",
    "\n",
    "ax.set_xlabel('cash-on-hand, $m$')\n",
    "ax.set_ylabel('durable, $d$')\n",
    "ax.set_xlim([0,3])\n",
    "ax.set_ylim([0.5,1.2])\n",
    "\n",
    "# set hline at n_grid[n_index]\n",
    "ax.axhline(models[('DP','1D')].egm.n_grid[n_index],lw=2,color='black',linestyle='--',label='n')\n",
    "\n",
    "ax.legend()\n",
    "filepath = f\"{folder}/DurablesModel_d_policy_DeepSimulate_D1.svg\"\n",
    "fig.savefig(filepath,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. <a id='toc10_2_'></a>[8D](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1. <a id='toc10_2_1_'></a>[Choose where to plot policy](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get means at t\n",
    "t = 5\n",
    "\n",
    "means = np.mean(models[('DeepSimulate','8D')].sim.states,axis=1)\n",
    "Nm = 100\n",
    "m_range = np.linspace(1e-8,5,Nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.2. <a id='toc10_2_2_'></a>[Get policy in levels](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DL POLICY FUNCTION AT CHOSEN POINTS\n",
    "\n",
    "algoname = 'DeepSimulate'\n",
    "\n",
    "# create model to get policy function\n",
    "par_dict = {'T':models[(algoname,'8D')].par.T,'D':models[(algoname,'8D')].par.D,'KKT':algoname=='DeepFOC','full':True}\n",
    "train_dict = {'Nneurons_policy':models[(algoname,'8D')].train.Nneurons_policy}\n",
    "model = DurablesModelClass(algoname = algoname,par=par_dict,train=train_dict,device='cpu')\n",
    "model.par.nu = model.par.tau = models[(algoname,'8D')].par.tau\n",
    "\n",
    "# load weights\n",
    "model.policy_NN.load_state_dict(models[(algoname,'8D')].policy_NN)\n",
    "\n",
    "# create state-tensor to compute policy on\n",
    "state_tensor = torch.zeros((Nm,model.par.Nstates+model.par.T),requires_grad=False)\n",
    "state_tensor[:,0] = torch.tensor(m_range,requires_grad=False)\n",
    "state_tensor[:,1] = torch.tensor(means[t,1],requires_grad=False)\n",
    "state_tensor[:,2:2+model.par.D] = torch.tensor(means[t,2:2+model.par.D],requires_grad=False)\n",
    "state_tensor[:,2+model.par.D+t] = 1\n",
    "\n",
    "# compute policy at these points\n",
    "policy = model.policy_NN(state_tensor)\n",
    "\n",
    "#  convert policy to levels\n",
    "c,d,a = compute_d_and_c_from_action(model.par,state_tensor,policy)\n",
    "c = c.detach().numpy()\n",
    "d = d.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.3. <a id='toc10_2_3_'></a>[Plot policy](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(9,6))\n",
    "\n",
    "# plot policy\n",
    "ax.plot(m_range,c,color=colors[0],lw=2)\n",
    "\n",
    "ax.set_xlabel('cash-on-hand, $m$')\n",
    "ax.set_ylabel('consumption, $c$')\n",
    "ax.set_xlim([0,5])\n",
    "ax.set_ylim([0.0,1.5])\n",
    "\n",
    "filepath = f\"{folder}/DurablesModel_c_policy_DeepSimulate_D8.svg\"\n",
    "fig.savefig(filepath,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(9,6))\n",
    "\n",
    "# plot policy\n",
    "for i_d in range(model.par.D):\n",
    "    ax.plot(m_range,d[:,i_d],label=f'$d_{i_d}$',color=colors[i_d],lw=2)\n",
    "\n",
    "ax.set_xlabel('cash-on-hand,$m$')\n",
    "ax.set_ylabel('durable goods, $d$')\n",
    "ax.set_xlim([0,5])\n",
    "ax.set_ylim([0.0,0.3])\n",
    "ax.legend(ncol=4)\n",
    "\n",
    "filepath = f\"{folder}/DurablesModel_d_policy_DeepSimulate_D8.svg\"\n",
    "fig.savefig(filepath,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. <a id='toc11_'></a>[More on convergence](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer in DeepExplore:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_base = deepcopy(model.sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.array([])\n",
    "neg = np.array([1,5,10,20,50,100,500,1000])\n",
    "transfer_grid = np.concatenate((-np.flip(neg),np.zeros(1),pos))/10_000\n",
    "R_transfer = np.zeros(transfer_grid.size)\n",
    "\n",
    "for i,transfer in enumerate(transfer_grid):\n",
    "\n",
    "    model.sim = deepcopy(sim_base)\n",
    "    model.sim.states[0,:,0] += transfer\n",
    "    model.simulate_R()\n",
    "    R_transfer[i] = model.sim.R\n",
    "\n",
    "    print(f'transfer = {transfer*10_000:-7.0f}, R = {R_transfer[i]:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mimic DP:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "model.sim = sim_base\n",
    "model.simulate_R()\n",
    "model.egm = SimpleNamespace()\n",
    "model.egm.transfer_grid = transfer_grid\n",
    "model.sim.R_transfer = R_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convergence plot:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 8\n",
    "Dstr = f'{D}D'\n",
    "specs = {(algoname,Dstr):algolabels[algoname] for algoname in algonames}\n",
    "convergence_plot('DurablesModel',models,specs,DP=model,do_transfer=True,\n",
    "                    xlim=xlim,ylim=[None,1],\n",
    "                    folder=folder,postfix=f'_{Dstr}_transfer_zoom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
